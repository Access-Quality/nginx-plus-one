name: Deploy EKS + Cine
run-name: "Deploy EKS + Cine (${{ github.ref_name }})"

on:
  workflow_dispatch:

permissions:
  contents: read
  packages: write # needed to push to ghcr.io

env:
  AWS_REGION: ${{ vars.AWS_REGION }}
  TF_CLOUD_ORGANIZATION: ${{ secrets.TFC_ORG }}
  TF_TOKEN_app_terraform_io: ${{ secrets.TFC_TOKEN }}

jobs:
  # ─────────────────────────────────────────────
  # Job 1 – Verify credentials & setup
  # ─────────────────────────────────────────────
  setup:
    name: Verify Credentials & Setup
    runs-on: ubuntu-latest
    outputs:
      account_id: ${{ steps.aws-identity.outputs.account_id }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Verify AWS identity & export account ID
        id: aws-identity
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "account_id=${ACCOUNT_ID}" >> $GITHUB_OUTPUT
          echo "AWS Account : ${ACCOUNT_ID}"
          echo "Region      : ${{ vars.AWS_REGION }}"
          echo "IAM caller  : $(aws sts get-caller-identity --query Arn --output text)"

      - name: Verify Terraform Cloud token
        run: |
          STATUS=$(curl -sf \
            --header "Authorization: Bearer ${{ secrets.TFC_TOKEN }}" \
            "https://app.terraform.io/api/v2/account/details" \
            | jq -r '.data.attributes.username')
          echo "TFC user: ${STATUS}"

  # ─────────────────────────────────────────────
  # Job 2 – Build & push Docker image
  # ─────────────────────────────────────────────
  build-image:
    name: Build & Push Docker Image
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      image: ${{ steps.meta.outputs.image }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push image
        id: meta
        run: |
          IMAGE="ghcr.io/${{ github.repository_owner }}/cine:${{ github.sha }}"
          docker buildx build \
            --platform linux/amd64 \
            --push \
            --tag "${IMAGE}" \
            nginx-eks/app/
          echo "image=${IMAGE}" >> $GITHUB_OUTPUT
          echo "Image pushed: ${IMAGE}"

  # ─────────────────────────────────────────────
  # Job 2b – Build & push Docker image (cine-tmdb)
  # ─────────────────────────────────────────────
  build-image-tmdb:
    name: Build & Push Docker Image (cine-tmdb)
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      image: ${{ steps.meta.outputs.image }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push image
        id: meta
        run: |
          IMAGE="ghcr.io/${{ github.repository_owner }}/cine-tmdb:${{ github.sha }}"
          docker buildx build \
            --platform linux/amd64 \
            --push \
            --tag "${IMAGE}" \
            nginx-eks/cine-tmdb/
          echo "image=${IMAGE}" >> $GITHUB_OUTPUT
          echo "Image pushed: ${IMAGE}"

  # ─────────────────────────────────────────────
  # Job 2c – Pull & push NGINX Plus NIC image
  #          (official image already ships nginx-agent)
  # ─────────────────────────────────────────────
  build-nic:
    name: Pull & Push NGINX Plus NIC Image
    runs-on: ubuntu-latest
    needs: setup
    outputs:
      image: ${{ steps.meta.outputs.image }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure Docker mTLS for private-registry.nginx.com
        run: |
          # private-registry.nginx.com uses mTLS client-cert auth.
          # Place cert/key where the Docker daemon expects them.
          sudo mkdir -p /etc/docker/certs.d/private-registry.nginx.com
          printf '%s' "${{ secrets.NGINX_REPO_CRT }}" \
            | sudo tee /etc/docker/certs.d/private-registry.nginx.com/client.cert > /dev/null
          printf '%s' "${{ secrets.NGINX_REPO_KEY }}" \
            | sudo tee /etc/docker/certs.d/private-registry.nginx.com/client.key > /dev/null
          sudo chmod 0400 \
            /etc/docker/certs.d/private-registry.nginx.com/client.cert \
            /etc/docker/certs.d/private-registry.nginx.com/client.key

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull official NIC image, retag and push to GHCR
        id: meta
        run: |
          # The official NIC+NAP WAF image already ships nginx-agent.
          # No custom Dockerfile needed — just retag and push to a registry
          # that the EKS cluster can pull from.
          DOCKERFILE="nginx-plus-one-eks/docker/nginx-nic/Dockerfile"
          echo "==> Dockerfile path: ${DOCKERFILE}"
          echo "==> Dockerfile exists: $(test -f "${DOCKERFILE}" && echo YES || echo NO)"
          NIC_VERSION=$(grep '^ARG NIC_VERSION' "${DOCKERFILE}" \
            | head -1 | cut -d= -f2 | tr -d '[:space:]')
          echo "==> NIC_VERSION parsed: '${NIC_VERSION}'"
          if [[ -z "${NIC_VERSION}" ]]; then
            echo "ERROR: could not parse NIC_VERSION from ${DOCKERFILE}"
            exit 1
          fi
          SRC="private-registry.nginx.com/nginx-ic-nap/nginx-plus-ingress:${NIC_VERSION}"
          IMAGE="ghcr.io/${{ github.repository_owner }}/nginx-nic:${{ github.sha }}"
          echo "==> SRC:   ${SRC}"
          echo "==> IMAGE: ${IMAGE}"
          docker pull "${SRC}"
          docker tag  "${SRC}" "${IMAGE}"
          docker push "${IMAGE}"
          echo "image=${IMAGE}" >> $GITHUB_OUTPUT
          echo "NIC image pushed: ${IMAGE}"

      - name: Clean up Docker mTLS certs
        if: always()
        run: sudo rm -rf /etc/docker/certs.d/private-registry.nginx.com

  # ─────────────────────────────────────────────
  # Job 3 – Terraform Plan
  # ─────────────────────────────────────────────
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: setup

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: nginx-eks/terraform/eks
        run: terraform init

      - name: Force-unlock workspace (if locked from a previous failed run)
        working-directory: nginx-eks/terraform/eks
        run: |
          WORKSPACE_ID=$(curl -sf \
            --header "Authorization: Bearer ${{ secrets.TFC_TOKEN }}" \
            --header "Content-Type: application/vnd.api+json" \
            "https://app.terraform.io/api/v2/organizations/${{ secrets.TFC_ORG }}/workspaces/nginx-eks" \
            | jq -r '.data.id')

          if [[ -z "${WORKSPACE_ID}" || "${WORKSPACE_ID}" == "null" ]]; then
            echo "No se pudo obtener el workspace ID. Continuando sin desbloquear."
            exit 0
          fi

          LOCKED=$(curl -sf \
            --header "Authorization: Bearer ${{ secrets.TFC_TOKEN }}" \
            --header "Content-Type: application/vnd.api+json" \
            "https://app.terraform.io/api/v2/workspaces/${WORKSPACE_ID}" \
            | jq -r '.data.attributes.locked')

          if [[ "${LOCKED}" == "true" ]]; then
            echo "Workspace bloqueado. Ejecutando force-unlock..."
            curl -sf \
              --header "Authorization: Bearer ${{ secrets.TFC_TOKEN }}" \
              --header "Content-Type: application/vnd.api+json" \
              --request POST \
              "https://app.terraform.io/api/v2/workspaces/${WORKSPACE_ID}/actions/force-unlock"
            echo "Workspace desbloqueado."
          else
            echo "Workspace libre. Continuando."
          fi

      - name: Terraform Validate
        working-directory: nginx-eks/terraform/eks
        run: terraform validate

      - name: Import orphaned AWS resources (if any)
        working-directory: nginx-eks/terraform/eks
        run: |
          ACCOUNT_ID=${{ needs.setup.outputs.account_id }}
          CLUSTER="nginx-eks"

          echo "Intentando importar recursos huérfanos (los errores se ignoran)..."

          terraform import \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            'module.eks.module.kms.aws_kms_alias.this["cluster"]' \
            "alias/eks/${CLUSTER}" 2>&1 | grep -v "already managed\|No changes" || true

          terraform import \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            'module.eks.aws_cloudwatch_log_group.this[0]' \
            "/aws/eks/${CLUSTER}/cluster" 2>&1 | grep -v "already managed\|No changes" || true

          terraform import \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            'module.eks.aws_iam_role.this[0]' \
            "${CLUSTER}-cluster-role" 2>&1 | grep -v "already managed\|No changes" || true

          terraform import \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            'module.eks.aws_iam_policy.custom[0]' \
            "arn:aws:iam::${ACCOUNT_ID}:policy/${CLUSTER}-cluster-role" 2>&1 | grep -v "already managed\|No changes" || true

          terraform import \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            'module.eks.module.eks_managed_node_group["default"].aws_iam_role.this[0]' \
            "${CLUSTER}-ng-role" 2>&1 | grep -v "already managed\|No changes" || true

          echo "Importación completada."

      - name: Terraform Plan
        working-directory: nginx-eks/terraform/eks
        run: |
          terraform plan \
            -var="aws_region=${{ vars.AWS_REGION }}" \
            -out=tfplan

      - name: Upload tfplan artifact
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: nginx-eks/terraform/eks/tfplan
          retention-days: 1

  # ─────────────────────────────────────────────
  # Job 4 – Terraform Apply
  # ─────────────────────────────────────────────
  terraform-apply:
    name: Terraform Apply
    runs-on: ubuntu-latest
    needs: terraform-plan
    outputs:
      cluster_name: ${{ steps.tf-output.outputs.cluster_name }}
      cluster_region: ${{ steps.tf-output.outputs.cluster_region }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Terraform Init
        working-directory: nginx-eks/terraform/eks
        run: terraform init

      - name: Download tfplan artifact
        uses: actions/download-artifact@v4
        with:
          name: tfplan
          path: nginx-eks/terraform/eks/

      - name: Terraform Apply
        working-directory: nginx-eks/terraform/eks
        run: terraform apply -auto-approve tfplan

      - name: Capture Terraform outputs
        id: tf-output
        working-directory: nginx-eks/terraform/eks
        run: |
          echo "cluster_name=$(terraform output -raw cluster_name)"     >> $GITHUB_OUTPUT
          echo "cluster_region=$(terraform output -raw cluster_region)" >> $GITHUB_OUTPUT

  # ─────────────────────────────────────────────
  # Job 5 – Install NGINX Plus Ingress Controller
  #          (NIC + App Protect WAF + NGINX Agent)
  # ─────────────────────────────────────────────
  setup-ingress:
    name: Install NGINX Plus NIC (NAP WAF + NGINX One Agent)
    runs-on: ubuntu-latest
    needs: [terraform-apply, build-nic]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.terraform-apply.outputs.cluster_region }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig \
            --region ${{ needs.terraform-apply.outputs.cluster_region }} \
            --name   ${{ needs.terraform-apply.outputs.cluster_name }}

      - name: Setup Helm
        uses: azure/setup-helm@v4

      - name: Uninstall OSS ingress-nginx (if present)
        run: |
          if helm status ingress-nginx -n ingress-nginx &>/dev/null; then
            echo "Removing OSS ingress-nginx..."
            helm uninstall ingress-nginx -n ingress-nginx --wait
          else
            echo "OSS ingress-nginx not found — skipping uninstall."
          fi

      - name: Create nginx-ingress namespace
        run: |
          kubectl create namespace nginx-ingress --dry-run=client -o yaml \
            | kubectl apply -f -

      - name: Create GHCR imagePullSecret for NIC
        run: |
          kubectl create secret docker-registry ghcr-secret \
            --docker-server=ghcr.io \
            --docker-username=${{ github.repository_owner }} \
            --docker-password=${{ secrets.GITHUB_TOKEN }} \
            --namespace nginx-ingress \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create NGINX Plus license secret
        run: |
          kubectl create secret generic nginx-license \
            --from-literal=license.jwt=${{ secrets.LICENSE_JWT }} \
            --from-literal=license.key=${{ secrets.LICENSE_KEY }} \
            --namespace nginx-ingress \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Create NGINX One data plane key secret
        # Secret key must be 'dataplane.key' — required by the Helm chart
        # nginxAgent.dataplaneKeySecretName value.
        # Ref: https://docs.nginx.com/nginx-one-console/k8s/add-nic/
        run: |
          kubectl create secret generic nginx-one-token \
            --from-literal=dataplane.key=${{ secrets.DATA_PLANE_KEY }} \
            --namespace nginx-ingress \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Install NGINX Plus NIC with App Protect WAF
        run: |
          NIC_IMAGE="${{ needs.build-nic.outputs.image }}"
          if [[ -z "${NIC_IMAGE}" ]]; then
            echo "ERROR: build-nic output image is empty"
            exit 1
          fi
          # Use the official OCI chart — it includes nginxAgent.* support
          # Ref: https://docs.nginx.com/nginx-one-console/k8s/add-nic/
          helm upgrade --install nginx-ingress \
            oci://ghcr.io/nginx/charts/nginx-ingress --version 2.4.4 \
            --namespace nginx-ingress \
            --values nginx-plus-one-eks/k8s/nginx-ic/nic-values.yaml \
            --set controller.image.repository="$(cut -d: -f1 <<< "${NIC_IMAGE}")" \
            --set controller.image.tag="$(cut -d: -f2 <<< "${NIC_IMAGE}")" \
            --wait \
            --timeout 10m

      - name: Apply WAF APPolicy + APLogConf
        run: |
          kubectl apply -f nginx-plus-one-eks/k8s/waf/waf-logconf.yaml
          kubectl apply -f nginx-plus-one-eks/k8s/waf/waf-policy.yaml
          echo "WAF policies applied."

      - name: Verify NIC deployment
        run: |
          kubectl rollout status deployment/nginx-ingress \
            -n nginx-ingress --timeout=3m
          kubectl get svc nginx-ingress -n nginx-ingress

  # ─────────────────────────────────────────────
  # Job 6 – Deploy the app
  # ─────────────────────────────────────────────
  deploy-app:
    name: Deploy Cine + Cine-TMDB
    runs-on: ubuntu-latest
    needs:
      [terraform-apply, setup-ingress, build-image, build-image-tmdb, build-nic]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.terraform-apply.outputs.cluster_region }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig \
            --region ${{ needs.terraform-apply.outputs.cluster_region }} \
            --name   ${{ needs.terraform-apply.outputs.cluster_name }}

      - name: Create OMDB API key secret
        run: |
          kubectl apply -f nginx-eks/k8s/namespace.yaml
          kubectl create secret generic omdb-secret \
            --from-literal=OMDB_API_KEY=${{ secrets.OMDB_API_KEY }} \
            --namespace cine \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Inject image into app.yaml
        run: |
          IMAGE="${{ needs.build-image.outputs.image }}"
          if [[ -z "${IMAGE}" ]]; then
            echo "ERROR: build-image output is empty"
            exit 1
          fi
          sed -i "s|IMAGE_PLACEHOLDER|${IMAGE}|g" nginx-eks/k8s/app.yaml
          echo "Image injected: ${IMAGE}"
          grep 'image:' nginx-eks/k8s/app.yaml

      - name: Apply Kubernetes manifests
        run: |
          kubectl apply -f nginx-eks/k8s/app.yaml
          kubectl apply -f nginx-eks/k8s/ingress.yaml
          echo "Manifests applied. Verifying deployment exists..."
          kubectl get deployment cine -n cine

      - name: Wait for Deployment rollout (cine)
        run: |
          echo "Esperando rollout completo del Deployment 'cine'..."
          kubectl rollout status deployment/cine -n cine --timeout=5m

      # ── cine-tmdb ──────────────────────────────────────────────────────────

      - name: Create TMDB API key secret
        run: |
          kubectl apply -f nginx-eks/k8s/cine-tmdb-namespace.yaml
          kubectl create secret generic tmdb-secret \
            --from-literal=TMDB_API_KEY=${{ secrets.TMDB_API_KEY }} \
            --namespace cine-tmdb \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Inject image into cine-tmdb-app.yaml
        run: |
          IMAGE="${{ needs.build-image-tmdb.outputs.image }}"
          if [[ -z "${IMAGE}" ]]; then
            echo "ERROR: build-image-tmdb output is empty"
            exit 1
          fi
          sed -i "s|CINE_TMDB_IMAGE_PLACEHOLDER|${IMAGE}|g" nginx-eks/k8s/cine-tmdb-app.yaml
          echo "Image injected: ${IMAGE}"

      - name: Apply cine-tmdb Kubernetes manifests
        run: |
          kubectl apply -f nginx-eks/k8s/cine-tmdb-app.yaml
          kubectl apply -f nginx-eks/k8s/cine-tmdb-ingress.yaml
          kubectl get deployment cine-tmdb -n cine-tmdb

      - name: Wait for Deployment rollout (cine-tmdb)
        run: |
          echo "Esperando rollout completo del Deployment 'cine-tmdb'..."
          kubectl rollout status deployment/cine-tmdb -n cine-tmdb --timeout=5m

      - name: Show Ingress LoadBalancer hostname and IP
        run: |
          echo "──────────────────────────────────────────────"
          echo "NGINX Plus Ingress external hostname:"
          HOSTNAME=$(kubectl get svc nginx-ingress \
            -n nginx-ingress \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          echo "${HOSTNAME}"

          echo ""
          echo "Waiting for DNS to resolve IP address..."
          IP=""
          ATTEMPTS=0
          MAX_ATTEMPTS=30   # 30 x 10s = 5 min máximo
          until [[ -n "${IP}" ]] || [[ ${ATTEMPTS} -ge ${MAX_ATTEMPTS} ]]; do
            IP=$(dig +short "${HOSTNAME}" | grep -E '^[0-9]+\.' | head -1)
            if [[ -z "${IP}" ]]; then
              ATTEMPTS=$((ATTEMPTS + 1))
              echo "  [${ATTEMPTS}/${MAX_ATTEMPTS}] Todavía propagando... reintentando en 10s"
              sleep 10
            fi
          done

          if [[ -n "${IP}" ]]; then
            echo "IP address: ${IP}"
          else
            echo "IP address: no resolvió en 5 minutos. Inténtalo manualmente con:"
            echo "  dig +short ${HOSTNAME}"
          fi

          echo ""
          echo "Point  cine.example.com       →  ${HOSTNAME}"
          echo "Point  cine-tmdb.example.com  →  ${HOSTNAME}"
          echo "──────────────────────────────────────────────"
